---
title: ReprÃ©sentation des nombres dÃ©cimaux et rÃ©els
weight: 4 
---

# ReprÃ©sentation des nombres dÃ©cimaux et rÃ©els ðŸŒ¡ï¸

Jusquâ€™Ã  prÃ©sent, nous avons travaillÃ© avec des **entiers**, quâ€™ils soient positifs, nÃ©gatifs, ou exprimÃ©s dans diffÃ©rentes bases.  
Mais dans le monde **rÃ©el** (sans jeu de mots ðŸ˜„), on manipule trÃ¨s souvent des **valeurs avec une partie dÃ©cimale** : prix, mesures, temps, pourcentagesâ€¦

Ces **nombres** posent un nouveau dÃ©fi pour les ordinateurs : comment les reprÃ©senter **avec un nombre fini de bits**, quand ils peuvent avoir **une infinitÃ© de dÃ©cimales** ?

Dans cette partie, nous allons voir :

- comment reprÃ©senter **des nombres avec une partie dÃ©cimale** en binaire ;
- pourquoi certaines valeurs **ne peuvent pas Ãªtre reprÃ©sentÃ©es exactement** ;
- ce que cela implique pour les calculs et les comparaisons ;
- et comment les ordinateurs utilisent une **reprÃ©sentation flottante** pour stocker ces nombres.

Pas besoin dâ€™entrer dans les dÃ©tails techniques des normes complexes : lâ€™objectif est de **comprendre les limites**, pas dâ€™apprendre par cÅ“ur leur structure binaire. ðŸ˜‰

---

## Convertir un nombre dÃ©cimal simple en binaire ðŸ”¢

Pour reprÃ©senter un **nombre dÃ©cimal** en binaire, on peut sÃ©parer le travail en deux parties :

- la **partie entiÃ¨re** se convertit comme un entier naturel (mÃ©thode dÃ©jÃ  vue),
- la **partie dÃ©cimale** se convertit Ã  lâ€™aide de **multiplications par 2** successives.


!!! methode "MÃ©thode : Convertir un nombre dÃ©cimal en binaire"
    Soit $x$ un nombre dÃ©cimal. On sÃ©pare $x$ en deux parties :
    
    - Partie entiÃ¨re : on applique la mÃ©thode des **divisions euclidiennes successives** (dÃ©jÃ  vue en base 2).
    - Partie dÃ©cimale : on effectue des **multiplications successives par 2**.
        - Ã€ chaque Ã©tape, la **partie entiÃ¨re du rÃ©sultat** donne le bit suivant.
        - La **partie dÃ©cimale restante** est Ã  multiplier Ã  nouveau par 2.
        - On continue jusquâ€™Ã  ce que la partie dÃ©cimale soit nulle (ou quâ€™on atteigne un nombre de bits fixÃ©).

=== "Exemple 1" 
    
    Nous allons convertir $6.25$ en binaire

    - Partie entiÃ¨re : $6 = 110_2$
    - Partie dÃ©cimale :   
        $0.25 \times 2 = 0.5$ â†’ 0  
        $0.5 \times 2 = 1.0$ â†’ 1  âœ… Fin : la partie dÃ©cimale est nulle

    $\Rightarrow \boxed{6.25_{10} = 110.01_2}$

=== "Exemple 2" 

    Nous allons convertir $0.75$ en binaire

    - Partie entiÃ¨re : $0 = 0_2$
    - Partie dÃ©cimale :  
        $0.75 \times 2 = 1.5$ â†’ 1  
        $0.5 \times 2 = 1.0$ â†’ 1  âœ… Fin : la partie dÃ©cimale est nulle

    $\Rightarrow \boxed{0.75_{10} = 0.11_2}$

=== "Exemple 3" 
    
    Nous allons convertir $0.1$ en binaire

    - Partie entiÃ¨re : $0 = 0_2$
    - Partie dÃ©cimale :  
        $0.1 \times 2 = 0.2$ â†’ 0  
        $0.2 \times 2 = 0.4$ â†’ 0  
        $0.4 \times 2 = 0.8$ â†’ 0  
        $0.8 \times 2 = 1.6$ â†’ 1  
        $0.6 \times 2 = 1.2$ â†’ 1  
        $0.2 \times 2 = 0.4$ â†’ 0  (ðŸ” on retombe sur $4$, la partie dÃ©cimale sera donc pÃ©riodique)

    $\Rightarrow \boxed{0.1_{10}}$ **nâ€™a pas dâ€™Ã©criture finie en binaire. Ainsi $\boxed{0,1 = 0,0\overline{0011}}$**


!!! info "Ã€ retenir"
    - Certains nombres dÃ©cimaux **ont une Ã©criture binaire finie** (comme $0.25$ ou $0.75$)
    - Dâ€™autres **ne peuvent pas Ãªtre reprÃ©sentÃ©s exactement** (comme $0.1$ ou $1/3$)
    - Cela entraÃ®ne des **erreurs dâ€™approximation** en machine

---

## Limites de la reprÃ©sentation et erreurs dâ€™approximation âš ï¸

Comme nous lâ€™avons vu, certains **nombres dÃ©cimaux** ne peuvent **pas Ãªtre reprÃ©sentÃ©s exactement** en binaire, Ã  cause des conversions ou du fait que lâ€™ordinateur **nâ€™a quâ€™un nombre limitÃ© de bits** pour coder un nombre rÃ©el.

ðŸ§  RÃ©sultat : les nombres sont souvent **approximÃ©s**, ce qui peut entraÃ®ner des **erreurs invisibles**â€¦ mais gÃªnantes dans les calculs.


### L'exemple typique `0.1 + 0.2 == 0.3` âŒ

Testons dans Python :

```python
>>> 0.1 + 0.2 == 0.3
False
>>> 0.1 + 0.2
0.30000000000000004
>>> 0.3
0.3
```

ðŸ˜± Pourtant, mathÃ©matiquement, $0.1 + 0.2 = 0.3$ !
Mais ici, lâ€™ordinateur approxime $0.1$ et $0.2$ en binaire, ce qui crÃ©e un petit dÃ©calage.

### Pourquoi Ã§a arrive ?

!!! info "Explication"
    
    - Les nombres sont codÃ©s en binaire flottant, avec un nombre limitÃ© de bits (ex : 32 ou 64).
    - Certaines fractions comme $0.1$ ont une Ã©criture infinie en binaire.
    - Lâ€™ordinateur tronque ou arrondit, ce qui crÃ©e une erreur dâ€™approximation.

### Comment gÃ©rer cela ?

De maniÃ¨re gÃ©nÃ©rale, il est donc fortement dÃ©conseillÃ© de comparer deux flottants avec `==` :

```python
>>> a = 0.1 + 0.2
>>> a == 0.3
False  # Ã  Ã©viter âŒ
```

Ã€ la place, on compare en autorisant une petite marge dâ€™erreur (appelÃ©e **epsilon**) :

```python
>>> abs((0.1+0.2) - 0.3) < 1e-9
True  # âœ… plus fiable !
```

!!! info "Ã€ retenir"
    - Les ordinateurs ne peuvent reprÃ©senter que des approximations de la plupart des rÃ©els.
    - Cela peut provoquer des erreurs dans les comparaisons ou les calculs en chaÃ®ne.
    - Il est conseillÃ© dâ€™utiliser `abs(a - b) < epsilon` pour comparer deux flottants.

---

## ReprÃ©sentation flottante des nombres rÃ©els ðŸŒŠ

Pour coder un rÃ©el comme $31.4159$, un ordinateur utilise un systÃ¨me proche de la **notation scientifique** :

$$
31.4159 = 3.14159 \times 10^1
$$

On peut faire la mÃªme chose **en base 2** :

$$
13.5 = 1101,1_2 = 1.1011_2 \times 2^3
$$

Cette maniÃ¨re dâ€™Ã©crire un nombre permet de **reprÃ©senter des valeurs trÃ¨s grandes ou trÃ¨s petites** avec un **nombre limitÃ© de bits**.


!!! definition "DÃ©finition : reprÃ©sentation en virgule flottante"
    Un **nombre en virgule flottante** est reprÃ©sentÃ© sous la forme :

    $$
    \text{valeur} = \text{signe} \times \text{mantisse} \times 2^{\text{exposant}}
    $$

    ---

    Dans l'exemple prÃ©cÃ©dent, on a :  

    - Signe : +
    - Mantisse : 1011
    - Exposant : 3


### Et dans la machine ? ðŸ’¾

La plupart des langages (dont Python, Java, Câ€¦) utilisent la **norme IEEE 754**. Cette norme dÃ©finit comment reprÃ©senter les rÃ©els avec **32 bits (float)** ou **64 bits (double)**.

!!! definition "Float : rÃ©el codÃ© en 32 bits (`float`)"
    - 1 bit pour le **signe** (0 ou 1)
    - 8 bits pour lâ€™**exposant** (avec un biais)
    - 23 bits pour la **mantisse**

!!! definition "Double : rÃ©el codÃ© en 64 bits (`double`)"
    - 1 bit pour le **signe** (0 ou 1)
    - 8 bits pour lâ€™**exposant** (avec un biais)
    - 23 bits pour la **mantisse**

!!! info "Ã€ retenir"
    â›” Pas besoin de savoir **comment** convertir un rÃ©el en binaire sur 32 bits (câ€™est hors programme),  
    âœ… Mais il faut comprendre :

    - quâ€™un rÃ©el est **reprÃ©sentÃ© en mantisse Ã— 2 exposant**,
    - que cette Ã©criture est **approximative** (limitÃ©e Ã  23 bits de prÃ©cision),
    - et quâ€™elle **explique les erreurs** vues prÃ©cÃ©demment.


--- 

Nous avons dÃ©sormais vu **comment reprÃ©senter des entiers et des rÃ©els en machine**.  
Ces connaissances seront essentielles pour mieux comprendre les **calculs**, les **structures de donnÃ©es**, et la **programmation de bas niveau** !